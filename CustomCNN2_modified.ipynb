{"cells": [{"cell_type": "code", "execution_count": 2, "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "38HFJsvGCPT9", "outputId": "88424134-453e-4900-c476-13f855d001b3"}, "outputs": [{"output_type": "stream", "name": "stdout", "text": ["Mounted at /content/drive\n", "Found 8741 images belonging to 2 classes.\n", "Found 2184 images belonging to 2 classes.\n"]}, {"output_type": "stream", "name": "stderr", "text": ["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n", "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n", "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n", "  self._warn_if_super_not_called()\n"]}, {"output_type": "stream", "name": "stdout", "text": ["Epoch 1/20\n", "\u001b[1m274/274\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m2337s\u001b[0m 8s/step - accuracy: 0.6503 - loss: 0.6783 - val_accuracy: 0.7674 - val_loss: 0.6060\n", "Epoch 2/20\n", "\u001b[1m274/274\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 199ms/step - accuracy: 0.8947 - loss: 0.2431 - val_accuracy: 0.7880 - val_loss: 0.6091\n", "Epoch 3/20\n", "\u001b[1m274/274\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 201ms/step - accuracy: 0.9415 - loss: 0.1338 - val_accuracy: 0.8077 - val_loss: 0.5496\n", "Epoch 4/20\n", "\u001b[1m274/274\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 201ms/step - accuracy: 0.9683 - loss: 0.0904 - val_accuracy: 0.8265 - val_loss: 0.6639\n", "Epoch 5/20\n", "\u001b[1m274/274\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 204ms/step - accuracy: 0.9871 - loss: 0.0379 - val_accuracy: 0.8370 - val_loss: 0.9304\n", "Epoch 6/20\n", "\u001b[1m274/274\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 199ms/step - accuracy: 0.9868 - loss: 0.0367 - val_accuracy: 0.8452 - val_loss: 0.7229\n", "Epoch 7/20\n", "\u001b[1m274/274\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 200ms/step - accuracy: 0.9906 - loss: 0.0320 - val_accuracy: 0.8274 - val_loss: 0.8749\n", "Epoch 8/20\n", "\u001b[1m274/274\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 240ms/step - accuracy: 0.9904 - loss: 0.0260 - val_accuracy: 0.8452 - val_loss: 0.9215\n", "Epoch 9/20\n", "\u001b[1m274/274\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 200ms/step - accuracy: 0.9941 - loss: 0.0157 - val_accuracy: 0.8443 - val_loss: 0.8792\n", "Epoch 10/20\n", "\u001b[1m274/274\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 202ms/step - accuracy: 0.9959 - loss: 0.0117 - val_accuracy: 0.8333 - val_loss: 0.8601\n", "Epoch 11/20\n", "\u001b[1m274/274\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 198ms/step - accuracy: 0.9950 - loss: 0.0160 - val_accuracy: 0.8379 - val_loss: 0.9583\n", "Epoch 12/20\n", "\u001b[1m274/274\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 197ms/step - accuracy: 0.9949 - loss: 0.0159 - val_accuracy: 0.8352 - val_loss: 0.9663\n", "Epoch 13/20\n", "\u001b[1m274/274\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 203ms/step - accuracy: 0.9953 - loss: 0.0152 - val_accuracy: 0.8352 - val_loss: 1.0176\n", "Epoch 14/20\n", "\u001b[1m274/274\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 210ms/step - accuracy: 0.9949 - loss: 0.0152 - val_accuracy: 0.8356 - val_loss: 1.3994\n", "Epoch 15/20\n", "\u001b[1m274/274\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 199ms/step - accuracy: 0.9955 - loss: 0.0156 - val_accuracy: 0.8375 - val_loss: 0.9261\n", "Epoch 16/20\n", "\u001b[1m274/274\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 199ms/step - accuracy: 0.9948 - loss: 0.0128 - val_accuracy: 0.8361 - val_loss: 1.1556\n", "Epoch 17/20\n", "\u001b[1m274/274\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 200ms/step - accuracy: 0.9934 - loss: 0.0172 - val_accuracy: 0.8402 - val_loss: 0.9708\n", "Epoch 18/20\n", "\u001b[1m274/274\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 202ms/step - accuracy: 0.9958 - loss: 0.0132 - val_accuracy: 0.8411 - val_loss: 1.1955\n", "Epoch 19/20\n", "\u001b[1m274/274\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 197ms/step - accuracy: 0.9958 - loss: 0.0140 - val_accuracy: 0.8365 - val_loss: 1.0879\n", "Epoch 20/20\n", "\u001b[1m274/274\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 200ms/step - accuracy: 0.9961 - loss: 0.0125 - val_accuracy: 0.8462 - val_loss: 1.2427\n", "\u001b[1m69/69\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 146ms/step\n", "Accuracy: 0.5064\n", "Precision: 0.4972\n", "Recall: 0.4888\n", "F1 Score: 0.4929\n", "Specificity: 0.5234\n"]}], "source": ["import tensorflow as tf\n", "from tensorflow import keras\n", "from tensorflow.keras import layers\n", "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n", "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n", "import numpy as np\n", "from google.colab import drive\n", "\n", "# Mount Google Drive\n", "drive.mount('/content/drive')\n", "\n", "# Define Image Size\n", "IMG_SIZE = (256, 256)  # Updated image size\n", "\n", "# Load Data\n", "data_dir = \"/content/drive/MyDrive/Converted Dataset\"\n", "datagen = ImageDataGenerator(validation_split=0.2, rescale=1./255)\n", "train_generator = datagen.flow_from_directory(\n", "    data_dir,\n", "    target_size=IMG_SIZE,\n", "    batch_size=32,\n", "    class_mode='binary',\n", "    subset='training'\n", ")\n", "val_generator = datagen.flow_from_directory(\n", "    data_dir,\n", "    target_size=IMG_SIZE,\n", "    batch_size=32,\n", "    class_mode='binary',\n", "    subset='validation'\n", ")\n", "\n", "# Build CNN Model\n", "model = keras.Sequential([\n", "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(256, 256, 3)),\n", "    layers.MaxPooling2D((2, 2)),\n", "    layers.Conv2D(64, (3, 3), activation='relu'),\n", "    layers.MaxPooling2D((2, 2)),\n", "    layers.Conv2D(128, (3, 3), activation='relu'),\n", "    layers.MaxPooling2D((2, 2)),\n", "    layers.Flatten(),\n", "    layers.Dense(128, activation='relu'),\n", "    layers.Dropout(0.5),\n", "    layers.Dense(1, activation='sigmoid')\n", "])\n", "\n", "# Compile Model\n", "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),\n", "              loss='binary_crossentropy',\n", "              metrics=['accuracy'])\n", "\n", "# Train Model\n", "epochs = 20\n", "history = model.fit(train_generator, epochs=epochs, validation_data=val_generator)\n", "\n", "# Evaluate model\n", "y_true = val_generator.classes\n", "y_pred = (model.predict(val_generator) > 0.5).astype(int).flatten()\n", "\n", "accuracy = accuracy_score(y_true, y_pred)\n", "precision = precision_score(y_true, y_pred)\n", "recall = recall_score(y_true, y_pred)\n", "f1 = f1_score(y_true, y_pred)\n", "cm = confusion_matrix(y_true, y_pred)\n", "specificity = cm[0, 0] / (cm[0, 0] + cm[0, 1])\n", "\n", "print(f\"Accuracy: {accuracy:.4f}\")\n", "print(f\"Precision: {precision:.4f}\")\n", "print(f\"Recall: {recall:.4f}\")\n", "print(f\"F1 Score: {f1:.4f}\")\n", "print(f\"Specificity: {specificity:.4f}\")\n", "# Print Metrics\n", "print(f\"Accuracy: {accuracy:.4f}\")\n", "print(f\"Precision: {precision:.4f}\")\n", "print(f\"Recall: {recall:.4f}\")\n", "print(f\"F1 Score: {f1:.4f}\")\n", "print(f\"Specificity: {specificity:.4f}\")\n"]}, {"cell_type": "code", "metadata": {}, "source": ["import torch\n", "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n", "import matplotlib.pyplot as plt\n\n", "# Save the model as 'heart1.pth'\n", "torch.save(model.state_dict(), 'heart1.pth')\n", "print(\"Model saved as 'heart1.pth'\")\n\n", "# Generate Confusion Matrix\n", "def plot_confusion_matrix(model, dataloader, device):\n", "    model.eval()\n", "    all_preds = []\n", "    all_labels = []\n", "    with torch.no_grad():\n", "        for inputs, labels in dataloader:\n", "            inputs, labels = inputs.to(device), labels.to(device)\n", "            outputs = model(inputs)\n", "            _, preds = torch.max(outputs, 1)\n", "            all_preds.extend(preds.cpu().numpy())\n", "            all_labels.extend(labels.cpu().numpy())\n", "    cm = confusion_matrix(all_labels, all_preds)\n", "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n", "    disp.plot(cmap='Blues')\n", "    plt.title('Confusion Matrix')\n", "    plt.show()\n"]}], "metadata": {"accelerator": "GPU", "colab": {"gpuType": "T4", "provenance": [], "toc_visible": true}, "kernelspec": {"display_name": "Python 3", "name": "python3"}, "language_info": {"name": "python"}}, "nbformat": 4, "nbformat_minor": 0}